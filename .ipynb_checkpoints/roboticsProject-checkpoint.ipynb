{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Thymio-Project\" data-toc-modified-id=\"Thymio-Project-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Thymio Project</a></span></li><li><span><a href=\"#Complete-Program\" data-toc-modified-id=\"Complete-Program-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Complete Program</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#define-the-state-machine\" data-toc-modified-id=\"define-the-state-machine-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>define the state machine</a></span><ul class=\"toc-item\"><li><span><a href=\"#define-the-Robot-object\" data-toc-modified-id=\"define-the-Robot-object-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>define the Robot object</a></span></li><li><span><a href=\"#Define-the-statefunctions\" data-toc-modified-id=\"Define-the-statefunctions-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Define the statefunctions</a></span></li></ul></li><li><span><a href=\"#......\" data-toc-modified-id=\"......-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>......</a></span></li><li><span><a href=\"#.........\" data-toc-modified-id=\".........-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>.........</a></span></li></ul></li><li><span><a href=\"#........\" data-toc-modified-id=\"........-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>........</a></span></li><li><span><a href=\"#Path-planning\" data-toc-modified-id=\"Path-planning-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Path planning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Initialise-path-planner\" data-toc-modified-id=\"Initialise-path-planner-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Initialise path planner</a></span></li><li><span><a href=\"#Planning-phase\" data-toc-modified-id=\"Planning-phase-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Planning phase</a></span></li><li><span><a href=\"#Query-Phase\" data-toc-modified-id=\"Query-Phase-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Query Phase</a></span></li><li><span><a href=\"#Getting-the-path\" data-toc-modified-id=\"Getting-the-path-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Getting the path</a></span></li><li><span><a href=\"#complete-pathplanning-demonstration\" data-toc-modified-id=\"complete-pathplanning-demonstration-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>complete pathplanning demonstration</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thymio Project\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:34:35.886396Z",
     "start_time": "2020-08-29T12:34:34.933996Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install pyserial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Program\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Import all the libraries needed to run the main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:52:42.121860Z",
     "start_time": "2020-08-29T12:52:42.112779Z"
    }
   },
   "outputs": [],
   "source": [
    "#import standart libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import serial\n",
    "import numpy as np\n",
    "from numpy import linalg as LNG \n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Adding the src folder in the current directory as it contains the script\n",
    "# with the Thymio class and all the files with the group generated functions and classes\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "from Thymio import Thymio\n",
    "#import functions made by group\n",
    "from pathPlanning import pathPlaning\n",
    "#import vision\n",
    "#import ANN\n",
    "#import robot_control\n",
    "import sys\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the state machine\n",
    "In this section the different states are defined as in the state machine graph shown earlier. The functions in this sections are named like the states they represent and they wrap the functions imported from the pathPlanning.py, test_vision.py,ANN.py and robot_control.py. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the Robot object\n",
    "This object contains all the variables needed in the state machine to make decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stateNames_t:\n",
    "    def __init__(self):\n",
    "        self.goalKnown='goalKnown'\n",
    "        self.planning='planning'\n",
    "        self.planAcquired='planAcquired'\n",
    "        self.newPath='newpath'\n",
    "        self.checkingPath='checkingPath'\n",
    "        self.underWay='underWay'\n",
    "        self.obstacleAvoidance='obstalceAvoidance'\n",
    "        self.goalReached='goalReached'\n",
    "class FSMHelper:\n",
    "    def __init__(self,thymio,kidnappingDistance,currentRobotPosition,equalTolerance,wayPointDistance):\n",
    "        self.kidnapDistance=kidnappingDistance\n",
    "        self.tolerance=equalTolerance\n",
    "        self.currentPosition=currentRobotPosition\n",
    "\n",
    "        self.newPositionEstimate=0    \n",
    "        self.thymio=thymio      \n",
    "        self.obstacleDetected=False\n",
    "        self.doStop=False\n",
    "        self.goalReached=True\n",
    "        self.goal=np.zeros((2,1))\n",
    "        self.pathToFollow=np.array([[0],[0]])\n",
    "        self.FSMStates=stateNames_t()\n",
    "        self.straightenedImage=0\n",
    "        self.wayPointReachedDistance=wayPointDistance\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the statefunctions\n",
    "In this section the different functions used to represent the states of the state machine are defined. Each function takes the FSMHelper object to make the decisions which state is the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goalKnown(robot):\n",
    "    if(LNG.norm(np.subtract(robot.currentGoal,robot.newGoal))>robot.tolerance):\n",
    "        robot.doStop=True\n",
    "        robot.currentGoal=robot.newGoal.copy()     \n",
    "        return robot.FSMStates.planning\n",
    "    else:\n",
    "        return robot.FSMStates.planAccuired\n",
    "def planning(robot):\n",
    "    robot.pathPlanner.setGoal(robot.currentGoal)\n",
    "    return robot.FSMStates.planAccuired\n",
    "def planAcquired(robot):\n",
    "    if(LNG.norm(np.subtract(robot.currentPosition,robot.newPositionEstimate))>robot.kidnappingDistance):\n",
    "        robot.pathPlanner.setStart(robot.newPositionEstimate)\n",
    "        robot.currentPosition=robot.newPositionEstimate\n",
    "        return robot.FSMStates.newPath\n",
    "    else:\n",
    "        return robot.FSMStates.checkingPath\n",
    "def newPath(robot):#pathPlanner,pathToFollow\n",
    "    robot.pathToFollow=robot.pathPlanner.getOptimizedPath()\n",
    "    return robot.FSMStates.checkingPath\n",
    "    \n",
    "def checkingPath(robot):\n",
    "    if(len(pathToFollow)):\n",
    "        robot_control.path_following(robot.pathToFollow)\n",
    "        return robot.FSMStates.underWay\n",
    "    else:  \n",
    "        robot.doStop=True\n",
    "        return robot.FSMStates.goalReached\n",
    "def underWay(robot):\n",
    "    if(robot.obstacleDetected==True):\n",
    "        return robot.FSMStates.obstacleAvoidance\n",
    "    else:\n",
    "        return robot.FSMStates.planAcquired\n",
    "def avoidObstacle(robot):     \n",
    "    ANN.run_ann_without_memory(robot.thymio)\n",
    "    return robot.FSMStates.checkingPath \n",
    "def goalReached(robot):\n",
    "    robot.goalReached=True\n",
    "    \n",
    "    \n",
    "#define the concrete stateName object to make the dictionary for the actual state machine\n",
    "stateName=stateNames_t()\n",
    "switch = {\n",
    "    stateName.goalKnown        : goalKnown,\n",
    "    stateName.planning         : planning,\n",
    "    stateName.planAcquired     : planAcquired,\n",
    "    stateName.newPath          : newPath,\n",
    "    stateName.checkingPath     : checkingPath,\n",
    "    stateName.underWay         : underWay,\n",
    "    stateName.obstacleAvoidance: avoidObstacle,\n",
    "    stateName.goalReached      : goalReached,\n",
    "}\n",
    "currentState=stateName.goalKnown\n",
    "futureState=stateName.goalKnown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ......\n",
    "The first steps are to try to connect to the camera and the thymio and then set different decision variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .........\n",
    "In this section the vision part is used to generate a map and then define a pathfinding object for that map. These section represents the 3 first states, since that division can be done in a Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th=Thymio.serial(port=\"COM5\", refreshing_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraIndex=1             #TODO: change it to the correct camera. currently uses webcam\n",
    "videoCapture = cv2.VideoCapture(cameraIndex)\n",
    "if not(videoCapture.isOpened()):\n",
    "    raise Exception('could not connect to camera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'test_vision_v2' has no attribute 'exposure'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-360b8606f530>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mimg_straighten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_vision_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfour_point_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorner_location\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mp2_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp98_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_straighten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m98\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mimg_res1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_vision_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexposure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrescale_intensity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_straighten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp2_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp98_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'test_vision_v2' has no attribute 'exposure'"
     ]
    }
   ],
   "source": [
    "import test_vision_v2\n",
    "from skimage import exposure\n",
    "cv2.namedWindow(\"preview\")\n",
    "cameraIndex=1             #TODO: change it to the correct camera. currently uses webcam\n",
    "videoCapture = cv2.VideoCapture(cameraIndex)\n",
    "print (videoCapture.set(cv2.CAP_PROP_EXPOSURE,-1))\n",
    "print (videoCapture.set(cv2.CAP_PROP_SATURATION ,120))\n",
    "\n",
    "if not(videoCapture.isOpened()):\n",
    "    raise Exception('could not connect to camera')\n",
    "\n",
    "if videoCapture.isOpened(): # try to get the first frame\n",
    "    rval, frame = videoCapture.read()\n",
    "    cv2.imshow(\"preview\", frame)\n",
    "else:\n",
    "    rval = False\n",
    "    raise Exception('could not connect to camera')\n",
    "cv2.imwrite('testMap.jpg',frame)\n",
    "#prepare mask and define realworld map dimension\n",
    "mask= cv2.imread('Images/mask.jpeg')\n",
    "if mask.size==0:\n",
    "    raise Exception('Could not open Mask')\n",
    "dimension_paper = [118.9,84.1] #cm A0\n",
    "dim = (int(dimension_paper[1]*2),int(dimension_paper[0]*2))\n",
    "# Switching red and blue channels\n",
    "frame[:, :, [0, 2]] = frame[:, :, [2, 0]]\n",
    "mask[:, :, [0, 2]] = mask[:, :, [2, 0]]\n",
    "corner_location = test_vision_v2.corner_detection(frame,mask)\n",
    "img_straighten, M = test_vision_v2.four_point_transform(mask, corner_location)\n",
    "p2_1, p98_1 = np.percentile(img_straighten, (2, 98))\n",
    "img_res1 = exposure.rescale_intensity(img_straighten, in_range=(p2_1,p98_1))\n",
    "\n",
    "\n",
    "## to visualize histograms\n",
    "img1_gray = cv2.cvtColor(img_res1, cv2.COLOR_BGR2GRAY)\n",
    "output = test_vision_v2.region_growing(img1_gray, (50,50))\n",
    "plt.imshow(output)\n",
    "plt.show()\n",
    "#obstacles = test_vision_v2.get_obstacles(frame,mask)\n",
    "#thymio_coord = test_vision_v2.get_thymio_info(frame,mask) # Do these online, and feed info to kalman filter\n",
    "#endpoint_coord = test_vision_v2.get_endpoint_info(frame,mask)\n",
    "#surgically_enhanced_obstacles = test_vision_v2.process_obstacles(obstacles)\n",
    "##make map\n",
    "#plt.imshow(obstacles)\n",
    "#plt.imshow(surgically_enhanced_obstacles)\n",
    "\n",
    "#transform provided image of the obstaclemap generator into occupancy grid\n",
    "#obstacles=cv2.resize(obstacles, dsize=(int(dim[1]/2), int(img_straighten.shape[0]*(dim[1]/2)/img_straighten.shape[1])))\n",
    "#occupancyGrid=obstacles[:,:,2]<200\n",
    "#occupancyGrid=occupancyGrid.astype(int)\n",
    "#plt.imshow(obstacles)\n",
    "#set occupancy marker to 1\n",
    "#pathPlanner=pathPlaning(occupancyGrid.copy(),1,1)\n",
    "\n",
    "#connect to the thymio,set the kinpapping distance to 10,the start position to (0,0) and the tolerance for equality to 1e-6, the distance when it is considered way point reached\n",
    "#robotStatus=FSMHelper(th,10,np.array([0,0]),1e-6,0.5)\n",
    "#estimatedRobotPose=startPose\n",
    "plt.imshow(frame)\n",
    "cv2.destroyAllWindows() \n",
    "cv2.VideoCapture(cameraIndex).release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "startTimer=timer()    #execution time when goal is set once\n",
    "#set goal\n",
    "goal=np.array([90,15])\n",
    "pathPlanner.setGoal(goal)\n",
    "\n",
    "endTimer=timer()\n",
    "print(\"Time needed for planning goal:\",endTimer-startTimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True -5.9\n",
      "True -5.800000000000001\n",
      "True -5.700000000000001\n",
      "True -5.600000000000001\n",
      "True -5.500000000000002\n",
      "True -5.400000000000002\n",
      "True -5.3000000000000025\n",
      "True -5.200000000000003\n",
      "True -5.100000000000003\n",
      "True -5.0000000000000036\n",
      "True -4.900000000000004\n",
      "True -4.800000000000004\n",
      "True -4.700000000000005\n",
      "True -4.600000000000005\n",
      "True 20\n",
      "True 30\n",
      "True 40\n",
      "True 50\n",
      "True 60\n",
      "True 70\n",
      "True 80\n",
      "True 90\n",
      "True 100\n",
      "True 110\n",
      "True 120\n",
      "False 130\n",
      "False 140\n",
      "False 150\n",
      "False 160\n",
      "False 170\n",
      "True -4.500000000000005\n",
      "True -4.400000000000006\n",
      "True -4.300000000000006\n",
      "True -4.200000000000006\n",
      "True -4.100000000000007\n",
      "True -4.000000000000007\n",
      "True -3.900000000000007\n",
      "True -3.800000000000007\n",
      "True -3.700000000000007\n",
      "True -3.6000000000000068\n",
      "True -3.5000000000000067\n",
      "True -3.4000000000000066\n",
      "True -3.3000000000000065\n",
      "True -3.2000000000000064\n",
      "True -3.1000000000000063\n",
      "True -3.000000000000006\n",
      "True -2.900000000000006\n",
      "True -2.800000000000006\n",
      "False 180\n",
      "False 190\n",
      "False 200\n",
      "True -2.700000000000006\n",
      "True -2.600000000000006\n",
      "False 190\n",
      "False 180\n",
      "False 170\n",
      "False 160\n",
      "False 150\n",
      "False 140\n",
      "False 130\n",
      "True 120\n",
      "True 110\n",
      "True 100\n",
      "True 90\n",
      "True 80\n",
      "True 70\n",
      "True 60\n",
      "True 50\n",
      "True 40\n",
      "True 30\n",
      "True 20\n",
      "True 10\n",
      "True 0\n",
      "True 10\n",
      "True 20\n",
      "True 30\n",
      "True 40\n",
      "True 50\n",
      "True 60\n",
      "True 70\n",
      "True 80\n",
      "True 90\n",
      "True 100\n",
      "True 110\n",
      "True 120\n",
      "False 130\n",
      "False 140\n",
      "False 150\n",
      "False 160\n",
      "False 170\n",
      "False 180\n",
      "False 190\n",
      "False 200\n",
      "False 210\n",
      "False 220\n",
      "False 230\n",
      "False 240\n",
      "False 250\n",
      "False 260\n",
      "False 270\n",
      "False 280\n",
      "False 290\n",
      "False 300\n",
      "False 310\n",
      "False 320\n",
      "False 330\n",
      "True -2.5000000000000058\n",
      "True -2.4000000000000057\n",
      "True -2.3000000000000056\n",
      "True -2.2000000000000055\n",
      "True -2.1000000000000054\n",
      "True -2.0000000000000053\n",
      "True -1.9000000000000052\n",
      "True -1.8000000000000052\n",
      "True -1.700000000000005\n",
      "True -1.600000000000005\n",
      "True -1.5000000000000049\n",
      "True -1.4000000000000048\n",
      "True -1.3000000000000047\n",
      "True -1.2000000000000046\n",
      "True -1.1000000000000045\n",
      "True -1.0000000000000044\n",
      "True -0.9000000000000045\n",
      "True -1.0000000000000044\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cv2.namedWindow(\"preview\")\n",
    "cameraIndex=1             #TODO: change it to the correct camera. currently uses webcam\n",
    "sat=10\n",
    "exp=-6\n",
    "videoCapture = cv2.VideoCapture(cameraIndex)\n",
    "print (videoCapture.set(cv2.CAP_PROP_EXPOSURE,-6))\n",
    "print (videoCapture.set(cv2.CAP_PROP_SATURATION ,10))\n",
    "if not(videoCapture.isOpened()):\n",
    "    raise Exception('could not connect to camera')\n",
    "\n",
    "if videoCapture.isOpened(): # try to get the first frame\n",
    "    rval, frame = videoCapture.read()\n",
    "else:\n",
    "    rval = False\n",
    "    print(\"no image\")\n",
    "\n",
    "while rval:\n",
    "    cv2.imshow(\"preview\", frame)\n",
    "    rval, frame = videoCapture.read()\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27: # exit on ESC\n",
    "        break\n",
    "    elif(key== ord('a')):\n",
    "        sat=sat+10\n",
    "        print (videoCapture.set(cv2.CAP_PROP_SATURATION ,sat),sat)\n",
    "    elif(key== ord('d')):\n",
    "        sat=sat-10\n",
    "        print (videoCapture.set(cv2.CAP_PROP_SATURATION ,sat),sat)\n",
    "    elif(key== ord('w')):\n",
    "        exp=exp+0.1\n",
    "        print (videoCapture.set(cv2.CAP_PROP_EXPOSURE,exp),exp)\n",
    "    elif(key== ord('s')):    \n",
    "        exp=exp-0.1\n",
    "        print (videoCapture.set(cv2.CAP_PROP_EXPOSURE,exp),exp)\n",
    "cv2.destroyWindow(\"preview\")\n",
    "cv2.destroyAllWindows() \n",
    "cv2.VideoCapture(cameraIndex).release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_thymio_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-fdf2f7caf490>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'could not read from camera'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mnewPicture\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnewPicture\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mthymio_coord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_thymio_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewPicture\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim_dim_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim_dim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Do these online, and feed info to kalman filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m#-----get odometrie data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mestimatedRobotPose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtimeElapsed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrobot_control\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0modometry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimatedRobotPose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtimeElapsed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrobot_control\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMAX_SPEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_thymio_info' is not defined"
     ]
    }
   ],
   "source": [
    "while(True):         #main execution loop\n",
    "    ##read sensors \n",
    "    \n",
    "    #----get robot position from camera\n",
    "    [frameCaptureSuccesfull,newPicture]=videoCapture.read()\n",
    "    if(frameCaptureSuccesfull==False):\n",
    "        raise Exception('could not read from camera')\n",
    "    newPicture[:, :, [0, 2]] = newPicture[:, :, [2, 0]]\n",
    "    thymio_coord = get_thymio_info(newPicture,M,im_dim_new,im_dim) # Do these online, and feed info to kalman filter\n",
    "    #-----get odometrie data\n",
    "    estimatedRobotPose,timeElapsed=robot_control.odometry(estimatedRobotPose,timeElapsed, robot_control.MAX_SPEED)\n",
    "    \n",
    "    #-----estimate current robot position\n",
    "    \n",
    "    robotStatus.newPositionEstimate=estimatedRobotPose[0:1]\n",
    "    \n",
    "    #check if unexcpected obstacle is present\n",
    "    robotStatus.obstacleDetected=not(all(sensorValues==0 for sensorValues in robotStatus.thymio[\"prox.horizontal\"]))\n",
    "    \n",
    "    #make desicions and work with the collected data \n",
    "    stateToExecute=switch.get(currentState)\n",
    "    futureState=stateToExecute(robotStatus)\n",
    "    \n",
    "    #doRobotControl here\n",
    "    robotStatus.pathToFollow=path_following(p, robotStatus.pathToFollow, THREASHOLD = 0.5)\n",
    "    \n",
    "    #stopping robot if goal reached end programm\n",
    "    if(robotStatus.doStop==True):\n",
    "        robotStatus.thymio.set_var(\"motor.left.target\", 0)\n",
    "        robotStatus.thymio.set_var(\"motor.right.target\", 0)\n",
    "    if(robotStatus.goalReached==True):\n",
    "        robotStatus.thymio.set_var(\"motor.left.target\", 0)\n",
    "        robotStatus.thymio.set_var(\"motor.right.target\", 0)\n",
    "        break\n",
    "    currentState=futureState\n",
    "    \n",
    "cv2.destroyAllWindows() \n",
    "cv2.VideoCapture(cameraIndex).release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows() \n",
    "cv2.VideoCapture(cameraIndex).release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "robotStatus.thymio.set_var(\"motor.left.target\", 00)\n",
    "robotStatus.thymio.set_var(\"motor.right.target\",00)\n",
    "#ANN.run_ann_without_memory(th)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ........\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having generated the map inside the computer with vision pathplanning is needed to create a path from the starting point to the goal. This is made possible by the pathplanning class.\n",
    "This class is used to create a pathplanning object, which is linked to a specific map, on which then all pathplanning is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise path planner\n",
    "To create the object the constructor of the class needs 3 things, The occupancy grid in form of a numpy array, with which number the occupied cells are marked and many CM represents one pixel(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:52:51.473548Z",
     "start_time": "2020-08-29T12:52:51.462661Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#imports needed to run pathplanning\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "#import pathplanning class\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "from pathPlanning import pathPlaning\n",
    "\n",
    "#load a testing map from image and convert it into a numpy array \n",
    "#(based on: https://www.pluralsight.com/guides/importing-image-data-into-numpy-arrays)\n",
    "pil_imgray = Image.open('Images/obstaclesTestMap.jpg').convert('LA')\n",
    "img = np.array(list(pil_imgray.getdata(band=0)), float)\n",
    "img.shape = (pil_imgray.size[1], pil_imgray.size[0])\n",
    "img=img<200\n",
    "occupancyGrid=img.astype(int)\n",
    "plt.imshow(occupancyGrid)\n",
    "##generate pathplanning object for the occupancy grid generated by the testmap\n",
    "pathPlanner=pathPlaning(occupancyGrid.copy(),1,1)#occipied cells are marked with a 1 and 1 cm per pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning phase\n",
    "Now that the pathplanning object has a map on which it should plan paths, the goal needs to be set by calling the \"setGoal\" method of the object and hand over a numpy array with the x,y coordinates of the goal.\\[x,y\\]. These coordinates are in cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTimer=timer()    #execution time when goal is set once\n",
    "#set goal\n",
    "goal=np.array([90,15])\n",
    "pathPlanner.setGoal(goal)\n",
    "\n",
    "endTimer=timer()\n",
    "print(\"Time needed for planning goal:\",endTimer-startTimer)\n",
    "\n",
    "startTimer=timer()    #execution time when goal is set again\n",
    "#set goal\n",
    "goal=np.array([90,15])\n",
    "pathPlanner.setGoal(goal)\n",
    "\n",
    "endTimer=timer()\n",
    "print(\"Time needed for planning for the same goal again:\",endTimer-startTimer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the \"setGoal\" method is called it simultaneously starts the planning phase. This does not mean that a path is planned but that the map is prepared to do fast pathplanning for each starting point one can come up with. This means that if the goal is often changed it will be a lot slower than a A*-pathplanner. If the goal stays the same and just the starting point changes often, it will be quite a bit faster. This is because in this planning phase, which is encapsulated in the private method \\_\\_generateGradient. In it a map is created, where for each grid cell its distance to the goal is calculated. This distance is a path distance, so the value saved means from the current cell you the robot has to move so many cells to reach the goal. This calculation is started from the goal and is made for every cell that is not marked occupied. The result is saved in the private distanceMap attribute, which can be accessed by a getter method \"getDistanceMap\". The occupied cells are left at the starting value of 0. This means during path generation the map needs to be checked whether the cell is occupied or not. But it also means that to make a path the path generator just has to \"roll\" down hill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the distance map visible\n",
    "distanceGrid=pathPlanner.getDistanceMap()\n",
    "fillUp=np.zeros_like(occupancyGrid)#helper to make picture 3 colors\n",
    "maxValue=np.amax(distanceGrid.transpose())   # normalize values to fit into picture\n",
    "#create picture to show  map and distance map\n",
    "pic=np.dstack((occupancyGrid,np.divide(distanceGrid,maxValue),fillUp))\n",
    "plt.imshow(pic)\n",
    "plt.scatter(goal[0],goal[1],marker=\"o\", color = 'yellow',s=200)\n",
    "plt.xlabel('X-direction')\n",
    "plt.ylabel('Y-direction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this picture,in red are the obstacles, in yellow the goal and in green the distance of the pixel to the goal in terms of how much movement would be needed to get to the goal.\n",
    "As can be seen surrounding the goal(the yellow point) are dark areas. This means those cells are very close to the goal. The greener the pixel is the longer the movement required to get to the goal from this pixel(cell). As can be seen if the goal is (90,15)(x,y) in the corner bottom left. There you can see a darker diagonal. This means if the robot is on those cells he needs to move less than if he is positioned at (80,20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Phase\n",
    "Now that the planning phase is over, the pathplanner is ready to provide paths to the goal from every free cell. To start the query phase and actually plan a path the start point needs to be provided. When the start point is provided, the class calls the private method \"\\_\\_generatePath\" to generate the path from the defined start point to the defined goal. For this the method begins at the starting point and looks for the cell, which has the smallest distance to goal of all its neighbors and puts the coordinates of that cell into the path. Of course only cells which are marked as free in the occupancy grid are checked. This goes on until th goal is reached. It is a bi comparable to rolling down a hill, since the cell from where the longest path to the goal exists is at the top of the hill.\n",
    "But this is only possible if \"setGoal\" was called atleast once before! Otherwise it can not find a path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:36:31.127153Z",
     "start_time": "2020-08-29T12:36:25.042891Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "startTimer=timer()\n",
    "start=np.array([10,75])\n",
    "pathPlanner.setStart(start)\n",
    "endTimer=timer()\n",
    "print(\"Time needed for the query for a new path:\",endTimer-startTimer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As may have been noticeable the query phase of the pathplanning is very fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the path\n",
    "Now that both planning and query phases are complete, the path can be extracted by calling the method \"getPath\" or \"getOptimizedPath\" The \"getPath\" method returns the path as a numpy array with the first line representing the x-coordinates and the second line representing the y coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unoptimizedPath=pathPlanner.getPath()\n",
    "print(unoptimizedPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"getoptimizedPath\" method returns a path where only the points, where the robot needs to turn, are retained. The path is output in the same format as the path from \"getPath\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizedPath=pathPlanner.getOptimizedPath()\n",
    "print(optimizedPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the 2 paths drawn onto the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(occupancyGrid)\n",
    "plt.plot(unoptimizedPath[0], unoptimizedPath[1], marker=\"o\", color = 'blue');\n",
    "plt.scatter(optimizedPath[0],optimizedPath[1], marker=\"o\", color = 'cyan',s=150)\n",
    "plt.xlabel('X-direction')\n",
    "plt.ylabel('Y-direction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cyan dots represent the optimized path and the blue dots represent the unoptimized path. As can be seen for the optimized path only the waypoints where the robot needs to change its orientation, are retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## complete pathplanning demonstration\n",
    "To see the complete Pathplanning on the testing map inaction this section can be run. To get a explanation of each part, see in the previous chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports needed to run pathplanning\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "#import pathplanning class\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "from pathPlanning import pathPlaning\n",
    "\n",
    "#load a testing map from image and convert it into a numpy array \n",
    "#(based on: https://www.pluralsight.com/guides/importing-image-data-into-numpy-arrays)\n",
    "pil_imgray = Image.open('Images/obstaclesTestMap.jpg').convert('LA')\n",
    "img = np.array(list(pil_imgray.getdata(band=0)), float)\n",
    "img.shape = (pil_imgray.size[1], pil_imgray.size[0])\n",
    "img=img<200\n",
    "occupancyGrid=img.astype(int)\n",
    "plt.imshow(occupancyGrid)\n",
    "##generate pathplanning object for the occupancy grid generated by the testmap\n",
    "pathPlanner=pathPlaning(occupancyGrid.copy(),1,1)#occipied cells are marked with a 1 and 1 cm per pixel\n",
    "\n",
    "#--set goal\n",
    "startTimer=timer()    #execution time when goal is set once\n",
    "#set goal\n",
    "goal=np.array([90,15])\n",
    "pathPlanner.setGoal(goal)\n",
    "\n",
    "endTimer=timer()\n",
    "print(\"Time needed for planning goal:\",endTimer-startTimer)\n",
    "#---set path\n",
    "startTimer=timer()\n",
    "start=np.array([10,75])\n",
    "pathPlanner.setStart(start)\n",
    "endTimer=timer()\n",
    "print(\"Time needed for the query for a new path:\",endTimer-startTimer)\n",
    "\n",
    "#--- get unoptimized path\n",
    "unoptimizedPath=pathPlanner.getPath()\n",
    "#-- get optimized Path\n",
    "optimizedPath=pathPlanner.getOptimizedPath()\n",
    "#--- draw all the components onto the same picture\n",
    "\n",
    "#make the distance map visible\n",
    "distanceGrid=pathPlanner.getDistanceMap()\n",
    "fillUp=np.zeros_like(occupancyGrid)#helper to make picture 3 colors\n",
    "maxValue=np.amax(distanceGrid.transpose())   # normalize values to fit into picture\n",
    "#create picture to show  map and distance map\n",
    "pic=np.dstack((occupancyGrid,np.divide(distanceGrid,maxValue),fillUp))\n",
    "plt.imshow(pic)\n",
    "plt.scatter(goal[0],goal[1],marker=\"o\", color = 'yellow',s=200)\n",
    "plt.xlabel('X-direction')\n",
    "plt.ylabel('Y-direction')\n",
    "plt.plot(unoptimizedPath[0], unoptimizedPath[1], marker=\"o\", color = 'blue');\n",
    "plt.scatter(optimizedPath[0],optimizedPath[1], marker=\"o\", color = 'cyan',s=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue points represent the unoptimized path, the cyan points are the optimized paths waypoint and red are the occupied cells. The green shade represents the distance of that pixel(cell) to the goal. The greener the longer is the path to the goal from that pixel(cell)\n",
    "As can be seen the path follows closely the obstacle. To prevent the robot from colliding with the obstacles, they need to be enlarged in the occupancy grid before the occupancy grid is given to the constructor. To see different behaviors the goal and start can be changed freely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "497.208px",
    "left": "281.667px",
    "right": "20px",
    "top": "62px",
    "width": "749px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
