{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Thymio-Project\" data-toc-modified-id=\"Thymio-Project-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Thymio Project</a></span></li><li><span><a href=\"#Complete-Program\" data-toc-modified-id=\"Complete-Program-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Complete Program</a></span><ul class=\"toc-item\"><li><span><a href=\"#Thymio-preparation\" data-toc-modified-id=\"Thymio-preparation-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Thymio preparation</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#define-the-state-machine\" data-toc-modified-id=\"define-the-state-machine-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>define the state machine</a></span><ul class=\"toc-item\"><li><span><a href=\"#define-the-Robot-object\" data-toc-modified-id=\"define-the-Robot-object-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>define the Robot object</a></span></li><li><span><a href=\"#Define-the-statefunctions\" data-toc-modified-id=\"Define-the-statefunctions-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Define the statefunctions</a></span></li></ul></li><li><span><a href=\"#......\" data-toc-modified-id=\"......-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>......</a></span></li><li><span><a href=\"#.........\" data-toc-modified-id=\".........-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>.........</a></span></li></ul></li><li><span><a href=\"#........\" data-toc-modified-id=\"........-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>........</a></span></li><li><span><a href=\"#Path-planning\" data-toc-modified-id=\"Path-planning-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Path planning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Initialise-path-planner\" data-toc-modified-id=\"Initialise-path-planner-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Initialise path planner</a></span></li><li><span><a href=\"#Planning-phase\" data-toc-modified-id=\"Planning-phase-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Planning phase</a></span></li><li><span><a href=\"#Query-Phase\" data-toc-modified-id=\"Query-Phase-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Query Phase</a></span></li><li><span><a href=\"#Getting-the-path\" data-toc-modified-id=\"Getting-the-path-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Getting the path</a></span></li><li><span><a href=\"#complete-pathplanning-demonstration\" data-toc-modified-id=\"complete-pathplanning-demonstration-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>complete pathplanning demonstration</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thymio Project\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:34:35.886396Z",
     "start_time": "2020-08-29T12:34:34.933996Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install pyserial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Program\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section  the main execution of the program is presented and available to be executed with a thymio that is properly prepared. \n",
    "## Thymio preparation\n",
    "The thymio should have 2 blue dots on it. 1 big, where the wheels are and 1 smaller on the front part. Those dots should be on a light blocking paper which is then mounted on the thymio. Furthermore there are some lights that can't be turned off. These should also be covered as well as possible.\n",
    "\n",
    "\n",
    "<img src=\"documentation/ImagesForDocumentation/\"\n",
    "     alt=\"Thymio Preparation\"\n",
    "     style=\"float: left; margin-right: 10px;\" />\n",
    "Image showing the top and side cover points\n",
    "<img src=\"documentation/ImagesForDocumentation/thymioBottom.jpg\"\n",
    "     alt=\"Thymio Preparation\"\n",
    "     style=\"float: left; margin-right: 10px;\" />\n",
    "\n",
    "\n",
    "Image showing the bottom spots to cover\n",
    "<img src=\"documentation/ImagesForDocumentation/thymioBehind.jpg\"\n",
    "     alt=\"Thymio Preparation\"\n",
    "     style=\"float: left; margin-right: 10px;\" />\n",
    "\n",
    "\n",
    "Image showing the behind spots to cover\n",
    "\n",
    "If all these spots are covered it wont confuse the vision system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main program consists out of three parts. One that takes data  from the different senors present. These are the camera, the horizontal facing infrared distance sensors and the internal speed measurement. These are then processed into the position and orientation of the robot and preprocessed to be able to make desicions in the second part. The second part is the state machine that takes the preprocessed data from the sensor part and decides whether it should "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Import all the libraries needed to run the main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:52:42.121860Z",
     "start_time": "2020-08-29T12:52:42.112779Z"
    }
   },
   "outputs": [],
   "source": [
    "#import standart libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import serial\n",
    "import numpy as np\n",
    "from numpy import linalg as LNG \n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from PIL import Image\n",
    "from skimage import exposure\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "# Adding the src folder in the current directory as it contains the script\n",
    "# with the Thymio class and all the files with the group generated functions and classes\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "from Thymio import Thymio\n",
    "#import functions made by group\n",
    "from pathPlanning import pathPlaning\n",
    "import ANN\n",
    "import robot_control\n",
    "import Vision\n",
    "import sys\n",
    "from timeit import default_timer as timer\n",
    "from kalman_filter import kalman_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the state machine\n",
    "In this section the different states are defined as in the state machine graph shown earlier. The functions in this sections are named like the states they represent and they wrap the functions imported from the pathPlanning.py, test_vision.py,ANN.py and robot_control.py. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the Robot object\n",
    "This object contains all the variables needed in the state machine to make decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stateNames_t:\n",
    "    def __init__(self):\n",
    "        self.planAcquired='planAcquired'\n",
    "        self.newPath='newpath'\n",
    "        self.checkingPath='checkingPath'\n",
    "        self.underWay='underWay'\n",
    "        self.obstacleAvoidance='obstalceAvoidance'\n",
    "        self.goalReached='goalReached'\n",
    "class FSMHelper:\n",
    "    def __init__(self,thymio,equalTolerance,wayPointDistance,pathplanner):\n",
    "        self.wasKidnapped=False\n",
    "        self.tolerance=equalTolerance\n",
    "        self.currentPosition=np.zeros((2,1))\n",
    "        self.pathPlanner=pathplanner\n",
    "        self.newPositionEstimate=0    \n",
    "        self.thymio=thymio      \n",
    "        self.obstacleDetected=False\n",
    "        self.doStop=False\n",
    "        self.goalReached=False\n",
    "        self.goal=np.zeros((2,1))\n",
    "        self.pathToFollow=np.array([[0],[0]])\n",
    "        self.FSMStates=stateNames_t()\n",
    "        self.straightenedImage=0\n",
    "        self.wayPointReachedDistance=wayPointDistance\n",
    "        self.followPath=False\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the statefunctions\n",
    "In this section the different functions used to represent the states of the state machine are defined. Each function takes the FSMHelper object to make the decisions which state is the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def planAcquired(robot):\n",
    "    if(robot.wasKidnapped==True):\n",
    "        robot.pathPlanner.setStart(robot.currentPosition[0:2])\n",
    "        return robot.FSMStates.newPath\n",
    "    else:\n",
    "        return robot.FSMStates.checkingPath\n",
    "def newPath(robot):#pathPlanner,pathToFollow\n",
    "    robot.pathToFollow=robot.pathPlanner.getOptimizedPath()\n",
    "    print(\"path after Planner\",robot.pathToFollow)\n",
    "    return robot.FSMStates.checkingPath\n",
    "    \n",
    "def checkingPath(robot):\n",
    "    #print(\"Size\",np.size(robot.pathToFollow))\n",
    "    if(np.size(robot.pathToFollow)!=0):\n",
    "        #print(\"path:\",robot.pathToFollow)\n",
    "        robot.followPath=True\n",
    "        return robot.FSMStates.underWay\n",
    "    else:\n",
    "        robot.followPath=False\n",
    "        robot.doStop=True\n",
    "        return robot.FSMStates.goalReached\n",
    "def underWay(robot):\n",
    "    if(robot.obstacleDetected==True):\n",
    "        robot.followPath=False\n",
    "        return robot.FSMStates.obstacleAvoidance\n",
    "    else:\n",
    "        return robot.FSMStates.planAcquired\n",
    "def avoidObstacle(robot):     \n",
    "    ANN.run_ann_without_memory(robot.thymio)\n",
    "    return robot.FSMStates.checkingPath \n",
    "def goalReached(robot):\n",
    "    robot.goalReached=True\n",
    "    \n",
    "    \n",
    "#define the concrete stateName object to make the dictionary for the actual state machine\n",
    "stateName=stateNames_t()\n",
    "switch = {\n",
    "    stateName.planAcquired     : planAcquired,\n",
    "    stateName.newPath          : newPath,\n",
    "    stateName.checkingPath     : checkingPath,\n",
    "    stateName.underWay         : underWay,\n",
    "    stateName.obstacleAvoidance: avoidObstacle,\n",
    "    stateName.goalReached      : goalReached,\n",
    "}\n",
    "currentState=stateName.planAcquired\n",
    "futureState=stateName.planAcquired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#possible struckture of main code chapter\n",
    "show state event diagramm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ......\n",
    "The first steps are to try to connect to the camera and the thymio and then set different decision variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .........\n",
    "In this section the vision part is used to generate a map and then define a pathfinding object for that map. These section represents the 3 first states, since that division can be done in a Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "th=Thymio.serial(port=\"COM6\", refreshing_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "th.set_var_array(\"leds.top\", [0, 0, 0])\n",
    "th.set_var_array(\"leds.bottom.right\", [0, 0, 0])\n",
    "th.set_var_array(\"leds.bottom.left\", [0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True -2.2\n",
      "True -2.3000000000000003\n",
      "True -2.4000000000000004\n",
      "True -2.5000000000000004\n",
      "True -2.6000000000000005\n",
      "True -2.7000000000000006\n",
      "True -2.8000000000000007\n",
      "True -2.900000000000001\n",
      "True -3.000000000000001\n",
      "True -3.100000000000001\n",
      "True -3.000000000000001\n",
      "True -2.900000000000001\n"
     ]
    }
   ],
   "source": [
    "cameraIndex=1             #index 1 is the index of the specific machine used. it is highly likly that it is on other machines aswell\n",
    "cv2.namedWindow(\"preview\")\n",
    "videoCapture = cv2.VideoCapture(cameraIndex)\n",
    "if not(videoCapture.isOpened()):\n",
    "    raise Exception('could not connect to camera')\n",
    "videoCapture = cv2.VideoCapture(cameraIndex)\n",
    "exposureOfCamera=-2.1          #initial exposure\n",
    "videoCapture.set(cv2.CAP_PROP_EXPOSURE,exposureOfCamera)\n",
    "videoCapture.set(cv2.CAP_PROP_SATURATION ,120)\n",
    "\n",
    "if not(videoCapture.isOpened()):\n",
    "    raise Exception('could not connect to camera')\n",
    "\n",
    "if videoCapture.isOpened(): # try to get the first frame\n",
    "    rval, frame = videoCapture.read()\n",
    "else:\n",
    "    rval = False\n",
    "    raise Exception('could not connect to camera')\n",
    "while rval:\n",
    "    cv2.imshow(\"preview\", frame)\n",
    "    rval, frame = videoCapture.read()\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27: # exit on ESC\n",
    "        break\n",
    "    elif(key== ord('w')):\n",
    "        exposureOfCamera=exposureOfCamera+0.1\n",
    "        print (videoCapture.set(cv2.CAP_PROP_EXPOSURE,exposureOfCamera),exposureOfCamera)\n",
    "    elif(key== ord('s')):    \n",
    "        exposureOfCamera=exposureOfCamera-0.1\n",
    "        print (videoCapture.set(cv2.CAP_PROP_EXPOSURE,exposureOfCamera),exposureOfCamera)\n",
    "cv2.destroyWindow(\"preview\")\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Coordinates:  (0.0, 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\Documents\\EPFL_Documents\\Mobile_Robotics_Master\\Mobile_Robotics\\Robotic_Project\\GithubRepo\\Mondadaa\\src\\Vision.py:277: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  slope = (bigpt[1]-smallpt[1])/(-bigpt[0]+smallpt[0]) # Obtain the slope of the thymio\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAD7CAYAAADXc3dDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPHElEQVR4nO3dXYwdZ33H8e+vXuIXaIJNsbuNoyZIVoAikdAVTZqqamNMQ0Cxb1IlEtWqsuQb2oYKCTnlAnGXiwrBRYtk8bYqaWgaQm1FCLAWUFUpCllIShMcYwhp4sZ405S3xo7Byb8XO4HFtbNnd5+zPrP+fqSjmeeZmcz/0To/zczZ2SdVhSRpeX7tfBcgSauBYSpJDRimktSAYSpJDRimktSAYSpJDSwrTJPckORwku8m2duqKEnqmyz190yTrAG+A+wAjgIPArdW1bfblSdJ/TC2jGPfCny3qh4HSPJZYCdwzjBds+GSGrtk81yjivWnn+eiF08vowRJWjk/fe7HnDx1MmfbtpwwvRR4al77KPB7L3fA2CWbGZ/8yC/a635+kuuP3r+MEiRp5dxz8M5zblvOM9OzpfP/e2aQZE+SmSQzL5z48a9se35s3TJOL0mjYzlhehS4bF57K/D0mTtV1b6qmqiqiTUbLvmVbetOP7+M00vS6FhOmD4IbEtyRZKLgFuAAwOf+MUXuPKHjy/j9JI0Opb8zLSqTif5C+BLwBrgk1X16Msdk3oRqlh3+nmu/OHjXPrc8aWeXpJGynK+gKKqvgB8YdD9L/7Zc9z4xFeXc0pJGkm+ASVJDRimktSAYSpJDRimktSAYSpJDRimktSAYSpJDRimktSAYSpJDRimktSAYSpJDRimktSAYSpJDRimktSAYSpJDRimktSAYSpJDSwYpkk+mWQ2ySPz+jYlOZjkSLfcONwyJWm0DXJl+mnghjP69gLTVbUNmO7aknTBWjBMq+pfgf85o3snMNWtTwG7GtclSb2y1GemW6rqGEC33NyuJEnqn6F/AZVkT5KZJDMnT50Y9ukk6bxYapgeTzIO0C1nz7VjVe2rqomqmli/dsMSTydJo22pYXoAmOzWJ4H9bcqRpH4a5Fej7gLuB65McjTJbuAOYEeSI8COri1JF6yxhXaoqlvPsWl741okqbd8A0qSGjBMJakBw1SSGjBMJakBw1SSGjBMJakBw1SSGjBMJakBw1SSGjBMJakBw1SSGjBMJakBw1SSGjBMJakBw1SSGjBMJakBw1SSGhhk2pLLknw1yaEkjya5revflORgkiPdcuPwy5Wk0TTIlelp4H1V9QbgGuA9Sd4I7AWmq2obMN21JemCtGCYVtWxqvpmt/5T4BBwKbATmOp2mwJ2DatISRp1i3pmmuRy4GrgAWBLVR2DucAFNp/jmD1JZpLMnDx1YnnVStKIGjhMk7wK+Bzw3qr6yaDHVdW+qpqoqon1azcspUZJGnkDhWmSVzAXpHdW1b1d9/Ek4932cWB2OCVK0ugb5Nv8AJ8ADlXVh+dtOgBMduuTwP725UlSP4wNsM91wJ8B/5Hk4a7vb4A7gLuT7AaeBG4eTomSNPoWDNOq+jcg59i8vW05ktRPvgElSQ0YppLUgGEqSQ0YppLUgGEqSQ0YppLUgGEqSQ0YppLUgGEqSQ0YppLUgGEqSQ0YppLUgGEqSQ0YppLUgGEqSQ0YppLUgGEqSQ0MMgfUuiRfT/LvSR5N8qGuf1OSg0mOdMuNwy9XkkbTIFemp4Drq+rNwFXADUmuAfYC01W1DZju2pJ0QVowTGvO/3bNV3SfAnYCU13/FLBrKBVKUg8M9Mw0yZpuZtJZ4GBVPQBsqapjAN1y8zmO3ZNkJsnMyVMnWtUtSSNloDCtqheq6ipgK/DWJG8a9ARVta+qJqpqYv3aDUutU5JG2qK+za+qHwFfA24AjicZB+iWs82rk6SeGOTb/NcmeXW3vh54G/AYcACY7HabBPYPq0hJGnVjA+wzDkwlWcNc+N5dVfcluR+4O8lu4Eng5iHWKUkjbcEwrapvAVefpf9ZYPswipKkvvENKElqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqYOAw7aZ7fijJfV17U5KDSY50y43DK1OSRttirkxvAw7Na+8FpqtqGzDdtSXpgjRQmCbZCrwT+Pi87p3AVLc+BexqW5ok9cegV6YfAd4PvDivb0tVHQPolpvPdmCSPUlmksycPHViWcVK0qhaMEyTvAuYrapvLOUEVbWvqiaqamL92g1L+U9I0shbcKpn4DrgpiQ3AuuAi5N8BjieZLyqjiUZB2aHWagkjbIFr0yr6vaq2lpVlwO3AF+pqncDB4DJbrdJYP/QqpSkEbec3zO9A9iR5Aiwo2tL0gVpkNv8X6iqrwFf69afBba3L0mS+sc3oCSpAcNUkhowTCWpAcNUkhowTCWpAcNUkhowTCWpAcNUkhowTCWpAcNUkhowTCWpAcNUkhowTCWpAcNUkhowTCWpAcNUkhowTCWpgYH+0n6SJ4CfAi8Ap6tqIskm4J+Ay4EngD+tqh8Op0xJGm2LuTL946q6qqomuvZeYLqqtgHTXVuSLkjLuc3fCUx161PAruWXI0n9NGiYFvDlJN9Isqfr21JVxwC65eazHZhkT5KZJDMnT51YfsWSNIIGnZ30uqp6Oslm4GCSxwY9QVXtA/YBbN70m7WEGiVp5A10ZVpVT3fLWeDzwFuB40nGAbrl7LCKlKRRt2CYJnllkl9/aR14O/AIcACY7HabBPYPq0hJGnWD3OZvAT6f5KX9/7GqvpjkQeDuJLuBJ4Gbh1emJI22BcO0qh4H3nyW/meB7cMoSpL6xjegJKkBw1SSGjBMJakBw1SSGjBMJakBw1SSGjBMJakBw1SSGjBMJakBw1SSGjBMJakBw1SSGjBMJakBw1SSGjBMJakBw1SSGjBMJamBgcI0yauT3JPksSSHklybZFOSg0mOdMuNwy5WkkbVoFemHwW+WFWvZ24Kk0PAXmC6qrYB011bki5Ig8xOejHwh8AnAKrqZ1X1I2AnMNXtNgXsGlaRkjTqBrkyfR3wDPCpJA8l+Xg35fOWqjoG0C03n+3gJHuSzCSZOXnqRLPCJWmUDBKmY8BbgI9V1dXAcyzilr6q9lXVRFVNrF+7YYllStJoGyRMjwJHq+qBrn0Pc+F6PMk4QLecHU6JkjT6FgzTqvoB8FSSK7uu7cC3gQPAZNc3CewfSoWS1ANjA+73l8CdSS4CHgf+nLkgvjvJbuBJ4ObhlChJo2+gMK2qh4GJs2za3rYcSeon34CSpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqYJCpnq9M8vC8z0+SvDfJpiQHkxzplhtXomBJGkWDzAF1uKquqqqrgN8FTgCfZ26G0umq2gZMs4gZSyVptVnsbf524HtV9Z/ATmCq658CdrUsTJL6ZLFhegtwV7e+paqOAXTLzS0Lk6Q+GThMu5lJbwL+eTEnSLInyUySmZOnTiy2PknqhcVcmb4D+GZVHe/ax5OMA3TL2bMdVFX7qmqiqibWr92wvGolaUQtJkxv5Ze3+AAHgMlufRLY36ooSeqbgcI0yQZgB3DvvO47gB1JjnTb7mhfniT1w9ggO1XVCeA1Z/Q9y9y3+5J0wfMNKElqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqwDCVpAYMU0lqYNBpS/46yaNJHklyV5J1STYlOZjkSLfcOOxiJWlULRimSS4F/gqYqKo3AWuAW4C9wHRVbQOmu7YkXZAGvc0fA9YnGQM2AE8DO4GpbvsUsKt9eZLUDwuGaVX9F/C3wJPAMeDHVfVlYEtVHev2OQZsHmahkjTKBrnN38jcVegVwG8Br0zy7kFPkGRPkpkkMydPnVh6pZI0wga5zX8b8P2qeqaqfg7cC/w+cDzJOEC3nD3bwVW1r6omqmpi/doNreqWpJEySJg+CVyTZEOSANuBQ8ABYLLbZxLYP5wSJWn0jS20Q1U9kOQe4JvAaeAhYB/wKuDuJLuZC9ybh1moJI2yBcMUoKo+CHzwjO5TzF2lStIFzzegJKkBw1SSGjBMJakBw1SSGkhVrdzJkmeA54D/XrGTDt9v4HhG2Woaz2oaC/RzPL9dVa8924YVDVOAJDNVNbGiJx0ixzPaVtN4VtNYYPWNx9t8SWrAMJWkBs5HmO47D+ccJscz2lbTeFbTWGCVjWfFn5lK0mrkbb4kNbCiYZrkhiSHk3w3Sa+mOUlyWZKvJjnUzYd1W9ff67mwkqxJ8lCS+7p2b8eT5NVJ7knyWPdzurbn4+n13GtJPplkNskj8/rOWX+S27tsOJzkT85P1Uu3YmGaZA3wd8A7gDcCtyZ540qdv4HTwPuq6g3ANcB7uvr7PhfWbcz9ScWX9Hk8HwW+WFWvB97M3Lh6OZ5VMvfap4Ebzug7a/3d/0u3AL/THfP3XWb0R1WtyAe4FvjSvPbtwO0rdf4hjGc/sAM4DIx3fePA4fNd2yLGsJW5f9DXA/d1fb0cD3Ax8H267wHm9fd1PJcCTwGbmPvrbvcBb+/beIDLgUcW+nmcmQfAl4Brz3f9i/ms5G3+S/84XnK06+udJJcDVwMP0O+5sD4CvB94cV5fX8fzOuAZ4FPdY4uPJ3klPR1Prd65185Vf+/zYSXDNGfp692vEiR5FfA54L1V9ZPzXc9SJXkXMFtV3zjftTQyBrwF+FhVXc3ca8ujfAv8spY791oP9T4fVjJMjwKXzWtvZW7K6N5I8grmgvTOqrq36x5oLqwRdB1wU5IngM8C1yf5DP0dz1HgaFU90LXvYS5c+zqeZc29NsLOVX/v82Elw/RBYFuSK5JcxNzD5gMreP5l6ea/+gRwqKo+PG9TL+fCqqrbq2prVV3O3M/iK1X1bvo7nh8ATyW5suvaDnybno6H1Tv32rnqPwDckmRtkiuAbcDXz0N9S7fCD6NvBL4DfA/4wPl+YLzI2v+AuduObwEPd58bgdcw9yXOkW656XzXuoSx/RG//AKqt+MBrgJmup/RvwAbez6eDwGPAY8A/wCs7dN4gLuYe977c+auPHe/XP3AB7psOAy843zXv9iPb0BJUgO+ASVJDRimktSAYSpJDRimktSAYSpJDRimktSAYSpJDRimktTA/wGGSvUbR/QRLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#cv2.namedWindow(\"preview\")\n",
    "videoCapture.set(cv2.CAP_PROP_EXPOSURE,-2.9)\n",
    "if videoCapture.isOpened(): # try to get the first frame\n",
    "    rval, frame = videoCapture.read()\n",
    "else:\n",
    "    rval = False\n",
    "    raise Exception('could not read image!')\n",
    "#read corner mask\n",
    "mask= cv2.imread('Images/Mondamask.JPG')\n",
    "if mask.size==0:\n",
    "    raise Exception('Could not open Mask')\n",
    "dimension_paper = [118.9,84.1] #cm A0\n",
    "dim = (int(dimension_paper[1]),int(dimension_paper[0]))\n",
    "# Switching red and blue channels\n",
    "frame[:, :, [0, 2]] = frame[:, :, [2, 0]]\n",
    "mask[:, :, [0, 2]] = mask[:, :, [2, 0]]\n",
    "#plt.imshow(frame)\n",
    "\n",
    "#plt.show()\n",
    "plt.imsave('maptest.jpg',frame)\n",
    "#preprocess image data to facilitate map generation and thymio position accusition\n",
    "p2_1, p98_1 = np.percentile(frame, (2, 98))\n",
    "img_res1 = exposure.rescale_intensity(frame, in_range=(p2_1,p98_1))\n",
    "img1_gray = cv2.cvtColor(img_res1, cv2.COLOR_BGR2GRAY)\n",
    "threshold_bg=130\n",
    "\n",
    "percent = 0.9\n",
    "while True:\n",
    "        output = Vision.bg_clustering(img1_gray, (50,50),threshold_bg)\n",
    "        corner_location = Vision.corner_detection(output,mask) # Get the location of the 4 corners\n",
    "        img_straighten, M = Vision.four_point_transform(frame, corner_location) # Get the transformation matrix and the straighten img\n",
    "        if(img_straighten.shape[0] > output.shape[0]*percent and img_straighten.shape[1] > output.shape[1]*percent):\n",
    "            break\n",
    "        else:\n",
    "            rval, frame = videoCapture.read()\n",
    "            frame[:, :, [0, 2]] = frame[:, :, [2, 0]]\n",
    "            print(\"Retake Picture, Webcame iz noobs\") # Command to retake the picture from webcam # Get the transformation matrix and the straighten img\n",
    "\n",
    "im_dim = img_straighten.shape\n",
    "obstacles = Vision.get_obstacles(img_straighten) # OFFLINE\n",
    "thymio_coord = Vision.get_thymio_info(frame,M,dim,im_dim) # Do these online, and feed info to kalman filter\n",
    "endpoint_coord = Vision.get_endpoint_info(frame,M,dim,im_dim)\n",
    "low_res_img = cv2.resize(img_straighten, dsize=((dim[1], dim[0])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "occupancyGrid=cv2.resize(obstacles, dsize=(int(dim[1]), int(dim[0])))\n",
    "occupancyGrid=occupancyGrid>200\n",
    "occupancyGrid=occupancyGrid.astype(float)\n",
    "kernel2 = np.ones((7,7), np.uint8)\n",
    "occupancyGrid = cv2.dilate(occupancyGrid, kernel2, iterations=2)\n",
    "plt.imshow(occupancyGrid)\n",
    "plt.show()\n",
    "#plt.imshow(occupancyGrid)\n",
    "pathPlanner=pathPlaning(occupancyGrid.copy(),1,1)\n",
    "#give over the thymio connection,set the kidnapping distance to 10 and the tolerance for equality to 1e-6, the distance when it is considered way point reached\n",
    "robotStatus=FSMHelper(th,1e-6,0.5,pathPlanner)\n",
    "robot_control.th=th\n",
    "#print(np.asarray(endpoint_coord))\n",
    "robotStatus.pathPlanner.setGoal(np.asarray(endpoint_coord))\n",
    "#print(np.asarray(thymio_coord[0]))\n",
    "robotStatus.currentPosition=np.array([(thymio_coord[0][0]),(thymio_coord[0][1]),(thymio_coord[1])/180*np.pi])\n",
    "#print(robotStatus.currentPosition[0:2])\n",
    "robotStatus.pathPlanner.setStart(robotStatus.currentPosition[0:2])\n",
    "robotStatus.pathToFollow=robotStatus.pathPlanner.getOptimizedPath()\n",
    "estimatedRobotPose=robotStatus.currentPosition\n",
    "\n",
    "#show path on image\n",
    "originalPath=robotStatus.pathToFollow.copy() \n",
    "\n",
    "plt.imshow(low_res_img)\n",
    "plt.scatter(thymio_coord[0][0],thymio_coord[0][1])\n",
    "plt.plot(originalPath[0],originalPath[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------WAYPOINT REACHED\n",
      "---------------------------------------------------------WAYPOINT REACHED\n",
      "---------------------------------------------------------WAYPOINT REACHED\n",
      "---------------------------------------------------------WAYPOINT REACHED\n",
      "---------------------------------------------------------WAYPOINT REACHED\n",
      "---------------------------------------------------------WAYPOINT REACHED\n",
      "---------------------------------------------------------WAYPOINT REACHED\n",
      "GOAL REACHED\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "#constant kalman matrixes\n",
    "\"\"\"\n",
    "A = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "C = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "Q = np.array([[5, 0, 0],[0, 5, 0],[0,0,5]]) # Dependent on the error (can be linked to stated as velocity, but velocity is not taken as state. )\n",
    "R = np.array([[0.01,0,0],[0,0.01,0],[0,0,0.01]])\n",
    "Q_ini = Q\n",
    "X = np.array([[estimatedRobotPose[0]],[estimatedRobotPose[1]],[estimatedRobotPose[2]]], dtype = \"float32\")\n",
    "print(X.size)\n",
    "L = []\n",
    "\"\"\"\n",
    "timeElapsed=np.array([0,0], dtype = 'float64')\n",
    "#print(\"robotstartPose\",robotStatus.currentPosition)\n",
    "robotPositionUncertainty=np.zeros((3,3))\n",
    "#print(robotStatus.pathToFollow)\n",
    "currentState=stateName.planAcquired\n",
    "futureState=stateName.planAcquired\n",
    "originalPath=robotStatus.pathToFollow.copy()    #times 2 becuase the vision system operates at 0.5 cm per pixel and the pathfinding at 1 cm per pixel\n",
    "doPlotCounter=0\n",
    "deltaT=0.0\n",
    "tbefore=time.time()\n",
    "tnow=0\n",
    "unfilteredCoordinates=list()\n",
    "filteredCoordinates=list()\n",
    "cutOfDistance=5\n",
    "cameraDataStableCounter=0\n",
    "cameraEstimate=robotStatus.currentPosition\n",
    "cameraData=True\n",
    "numberOfStableMeasurments=10\n",
    "while(True):         #main execution loop\n",
    "    ##read sensors    \n",
    "    #----get robot position from camera\n",
    "    [frameCaptureSuccesfull,newPicture]=videoCapture.read()\n",
    "    if(frameCaptureSuccesfull==False):\n",
    "        raise Exception('could not read from camera')\n",
    "    newPicture[:, :, [0, 2]] = newPicture[:, :, [2, 0]]\n",
    "    thymio_coord = Vision.get_thymio_info(newPicture,M,dim,im_dim) # Do these online, and feed info to kalman filter\n",
    "    ###---------------camera data true\n",
    "    if(cameraData==True):\n",
    "        newCameraEstimate=np.array([thymio_coord[0][0],thymio_coord[0][1],thymio_coord[1]/180.0*np.pi])\n",
    "        unfilteredCoordinates.append((cameraEstimate[0],cameraEstimate[1]))\n",
    "        \n",
    "        if(LNG.norm(newCameraEstimate[0:2]-cameraEstimate[0:2])<cutOfDistance):\n",
    "            cameraDataStableCounter=cameraDataStableCounter+1\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            cameraDataStableCounter=0\n",
    "        cameraEstimate=newCameraEstimate\n",
    "   \n",
    "    #print(\"cameraEstimate\",cameraEstimate,\"ThymioCoordinate\",thymio_coord)   \n",
    "    #print(\"CurrentPosition\",robotStatus.currentPosition)\n",
    "    #-----get odometrie data\n",
    "    #print(\"before odometry\",robotStatus.currentPosition)\n",
    "    estimatedRobotPose,robotPositionUncertainty,timeElapsed=robot_control.odometry(robotStatus.currentPosition,robotPositionUncertainty,timeElapsed, robot_control.MAX_SPEED)\n",
    "    \"\"\"plt.scatter(estimatedRobotPose[0],estimatedRobotPose[1])\n",
    "    plt.show()\"\"\"\n",
    "    \"\"\"\n",
    "    V_left=th[\"motor.left.speed\"]*0.0135\n",
    "    V_right=th[\"motor.right.speed\"]*0.0135\n",
    "    v_avg = (V_left + V_right)/2\n",
    "    v_delta = V_left- V_right\n",
    "    \"\"\"\n",
    "    #-----estimate current robot position\n",
    "    tnow=time.time()\n",
    "    deltaT=tnow-tbefore\n",
    "    #print(\"deltaT\",deltaT)\n",
    "    tbefore=tnow\n",
    "    \"\"\"\n",
    "    B = np.array([[(math.cos(cameraEstimate[2])),0.], [(math.sin(cameraEstimate[2])), 0.], [0.,1.]])\n",
    "    Z = np.array([[cameraEstimate[0]],[cameraEstimate[1]],[cameraEstimate[2]]], dtype = \"float32\")\n",
    "    u = np.array([[v_avg*deltaT],[v_delta*deltaT]])\n",
    "    \"\"\"\n",
    "    #print(u)\n",
    "    #thymio_position,cov = kalman_filt(X,u,Q_ini,Z,A,B,C,Q,R)\n",
    "    \n",
    "    #X = thymio_position\n",
    "    #Q_ini = cov\n",
    "    \"\"\"#data accusition\n",
    "    print(\"Camera Estimate:\",cameraEstimate)\n",
    "    print(\"leftmotor:\",th[\"motor.left.speed\"])\n",
    "    print(\"rightmotor:\",th[\"motor.right.speed\"])\n",
    "    \n",
    "    \"\"\"\n",
    "    #if(cameraDataStableCounter>numberOfStableMeasurments):\n",
    "        #print(cameraDataStableCounter)\n",
    "    if(cameraData==True and (LNG.norm(estimatedRobotPose[0:2]-cameraEstimate[0:2])<cutOfDistance or cameraDataStableCounter>numberOfStableMeasurments)):\n",
    "        robotStatus.currentPosition=cameraEstimate\n",
    "    else:\n",
    "        robotStatus.currentPosition=estimatedRobotPose #np.transpose(X).flatten()\n",
    "    filteredCoordinates.append((robotStatus.currentPosition[0],robotStatus.currentPosition[1]))\n",
    "    #print(\"stuff\",robotStatus.newPositionEstimate)\n",
    "    #------------check if unexcpected obstacle is present\n",
    "    robotStatus.obstacleDetected=not(all(sensorValues==0 for sensorValues in robotStatus.thymio[\"prox.horizontal\"]))\n",
    "    #print(\"ObstacleDetected\",robotStatus.obstacleDetected)\n",
    "    #if(cameraData==True):\n",
    "        #robotStatus.currentPosition\n",
    "   \n",
    "    \n",
    "    \n",
    "    #------------------------------make desicions and work with the collected data \n",
    "    \n",
    "    \n",
    "    \n",
    "    stateToExecute=switch.get(currentState)\n",
    "    #print(currentState)\n",
    "    futureState=stateToExecute(robotStatus)\n",
    "    \n",
    "    #doRobotControl here\n",
    "    #_,robotStatus.pathToFollow=robot_control.path_following(robotStatus.currentPosition, robotStatus.pathToFollow, THREASHOLD = 0.5)\n",
    "    \n",
    "    #stopping robot if goal reached end programm\n",
    "    if(robotStatus.followPath==True and np.size(robotStatus.pathToFollow)!=0):\n",
    "        _,robotStatus.pathToFollow=robot_control.path_following(robotStatus.currentPosition,robotStatus.pathToFollow)\n",
    "    if(robotStatus.doStop==True):\n",
    "        robotStatus.thymio.set_var(\"motor.left.target\", 0)\n",
    "        robotStatus.thymio.set_var(\"motor.right.target\", 0)\n",
    "    if(robotStatus.goalReached==True):\n",
    "        robotStatus.thymio.set_var(\"motor.left.target\", 0)\n",
    "        robotStatus.thymio.set_var(\"motor.right.target\", 0)\n",
    "        break\n",
    "    currentState=futureState\n",
    "    doPlotCounter=doPlotCounter+1\n",
    "    if(doPlotCounter>10 or robotStatus.goalReached==True):\n",
    "        doPlotCounter=0\n",
    "        low_res_img = cv2.resize(newPicture, dsize=((dim[1], dim[0])))\n",
    "        low_res_img[:, :, [0, 2]] = low_res_img[:, :, [2, 0]]\n",
    "        low_res_img = cv2.circle(low_res_img, (int(robotStatus.currentPosition[0]),int(robotStatus.currentPosition[1])), radius=2, color=(0, 0, 255), thickness=-1)\n",
    "        cv2.circle(low_res_img, (int(cameraEstimate[0]),int(cameraEstimate[1])), radius=10, color=(0, 255, 0), thickness=2)\n",
    "        cv2.circle(low_res_img, (int(estimatedRobotPose[0]),int(estimatedRobotPose[1])), radius=8, color=(255, 0, 0), thickness=2)\n",
    "        cv2.circle(low_res_img, (int(robotStatus.currentPosition[0]),int(robotStatus.currentPosition[1])), radius=16, color=(255, 0, 0), thickness=2)\n",
    "        cv2.imshow(\"Display window\",low_res_img)\n",
    "        if(robotStatus.goalReached):\n",
    "            cv2.waitKey(0)\n",
    "        else:\n",
    "            cv2.waitKey(1)\n",
    "        #plt.scatter(thymio_coord[0][0],thymio_coord[0][1])\n",
    "        #plt.plot(originalPath[0],originalPath[1])\n",
    "        #print(\"odometrie estimate\",estimatedRobotPose)\n",
    "        #plt.scatter(estimatedRobotPose[0],estimatedRobotPose[1])\n",
    "        #plt.show()\n",
    "unfilteredCoordinates=np.array(unfilteredCoordinates).reshape(-1, 2).transpose()\n",
    "filteredCoordinates=np.array(filteredCoordinates).reshape(-1, 2).transpose()\n",
    "plt.plot(unfilteredCoordinates[0],unfilteredCoordinates[1],label=\"Measured\")\n",
    "plt.plot(filteredCoordinates[0],filteredCoordinates[1],label=\"filtered\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "cv2.destroyAllWindows() \n",
    "cv2.VideoCapture(cameraIndex).release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows() \n",
    "cv2.VideoCapture(cameraIndex).release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "th.set_var(\"motor.left.target\", 00)\n",
    "th.set_var(\"motor.right.target\",00)\n",
    "#ANN.run_ann_without_memory(th)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ........\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having generated the map inside the computer with vision pathplanning is needed to create a path from the starting point to the goal. This is made possible by the pathplanning class.\n",
    "This class is used to create a pathplanning object, which is linked to a specific map, on which then all pathplanning is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise path planner\n",
    "To create the object the constructor of the class needs 3 things, The occupancy grid in form of a numpy array, with which number the occupied cells are marked and many CM represents one pixel(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:52:51.473548Z",
     "start_time": "2020-08-29T12:52:51.462661Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#imports needed to run pathplanning\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "#import pathplanning class\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "from pathPlanning import pathPlaning\n",
    "\n",
    "#load a testing map from image and convert it into a numpy array \n",
    "#(based on: https://www.pluralsight.com/guides/importing-image-data-into-numpy-arrays)\n",
    "pil_imgray = Image.open('Images/obstaclesTestMap.jpg').convert('LA')\n",
    "img = np.array(list(pil_imgray.getdata(band=0)), float)\n",
    "img.shape = (pil_imgray.size[1], pil_imgray.size[0])\n",
    "img=img<200\n",
    "occupancyGrid=img.astype(int)\n",
    "plt.imshow(occupancyGrid)\n",
    "##generate pathplanning object for the occupancy grid generated by the testmap\n",
    "pathPlanner=pathPlaning(occupancyGrid.copy(),1,1)#occipied cells are marked with a 1 and 1 cm per pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning phase\n",
    "Now that the pathplanning object has a map on which it should plan paths, the goal needs to be set by calling the \"setGoal\" method of the object and hand over a numpy array with the x,y coordinates of the goal.\\[x,y\\]. These coordinates are in cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTimer=timer()    #execution time when goal is set once\n",
    "#set goal\n",
    "goal=np.array([90,15])\n",
    "pathPlanner.setGoal(goal)\n",
    "\n",
    "endTimer=timer()\n",
    "print(\"Time needed for planning goal:\",endTimer-startTimer)\n",
    "\n",
    "startTimer=timer()    #execution time when goal is set again\n",
    "#set goal\n",
    "goal=np.array([90,15])\n",
    "pathPlanner.setGoal(goal)\n",
    "\n",
    "endTimer=timer()\n",
    "print(\"Time needed for planning for the same goal again:\",endTimer-startTimer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the \"setGoal\" method is called it simultaneously starts the planning phase. This does not mean that a path is planned but that the map is prepared to do fast pathplanning for each starting point one can come up with. This means that if the goal is often changed it will be a lot slower than a A*-pathplanner. If the goal stays the same and just the starting point changes often, it will be quite a bit faster. This is because in this planning phase, which is encapsulated in the private method \\_\\_generateGradient. In it a map is created, where for each grid cell its distance to the goal is calculated. This distance is a path distance, so the value saved means from the current cell you the robot has to move so many cells to reach the goal. This calculation is started from the goal and is made for every cell that is not marked occupied. The result is saved in the private distanceMap attribute, which can be accessed by a getter method \"getDistanceMap\". The occupied cells are left at the starting value of 0. This means during path generation the map needs to be checked whether the cell is occupied or not. But it also means that to make a path the path generator just has to \"roll\" down hill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the distance map visible\n",
    "distanceGrid=pathPlanner.getDistanceMap()\n",
    "fillUp=np.zeros_like(occupancyGrid)#helper to make picture 3 colors\n",
    "maxValue=np.amax(distanceGrid.transpose())   # normalize values to fit into picture\n",
    "#create picture to show  map and distance map\n",
    "pic=np.dstack((occupancyGrid,np.divide(distanceGrid,maxValue),fillUp))\n",
    "plt.imshow(pic)\n",
    "plt.scatter(goal[0],goal[1],marker=\"o\", color = 'yellow',s=200)\n",
    "plt.xlabel('X-direction')\n",
    "plt.ylabel('Y-direction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this picture,in red are the obstacles, in yellow the goal and in green the distance of the pixel to the goal in terms of how much movement would be needed to get to the goal.\n",
    "As can be seen surrounding the goal(the yellow point) are dark areas. This means those cells are very close to the goal. The greener the pixel is the longer the movement required to get to the goal from this pixel(cell). As can be seen if the goal is (90,15)(x,y) in the corner bottom left. There you can see a darker diagonal. This means if the robot is on those cells he needs to move less than if he is positioned at (80,20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Phase\n",
    "Now that the planning phase is over, the pathplanner is ready to provide paths to the goal from every free cell. To start the query phase and actually plan a path the start point needs to be provided. When the start point is provided, the class calls the private method \"\\_\\_generatePath\" to generate the path from the defined start point to the defined goal. For this the method begins at the starting point and looks for the cell, which has the smallest distance to goal of all its neighbors and puts the coordinates of that cell into the path. Of course only cells which are marked as free in the occupancy grid are checked. This goes on until th goal is reached. It is a bi comparable to rolling down a hill, since the cell from where the longest path to the goal exists is at the top of the hill.\n",
    "But this is only possible if \"setGoal\" was called atleast once before! Otherwise it can not find a path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:36:31.127153Z",
     "start_time": "2020-08-29T12:36:25.042891Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "startTimer=timer()\n",
    "start=np.array([10,75])\n",
    "pathPlanner.setStart(start)\n",
    "endTimer=timer()\n",
    "print(\"Time needed for the query for a new path:\",endTimer-startTimer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As may have been noticeable the query phase of the pathplanning is very fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the path\n",
    "Now that both planning and query phases are complete, the path can be extracted by calling the method \"getPath\" or \"getOptimizedPath\" The \"getPath\" method returns the path as a numpy array with the first line representing the x-coordinates and the second line representing the y coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unoptimizedPath=pathPlanner.getPath()\n",
    "print(unoptimizedPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"getoptimizedPath\" method returns a path where only the points, where the robot needs to turn, are retained. The path is output in the same format as the path from \"getPath\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizedPath=pathPlanner.getOptimizedPath()\n",
    "print(optimizedPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the 2 paths drawn onto the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(occupancyGrid)\n",
    "plt.plot(unoptimizedPath[0], unoptimizedPath[1], marker=\"o\", color = 'blue');\n",
    "plt.scatter(optimizedPath[0],optimizedPath[1], marker=\"o\", color = 'cyan',s=150)\n",
    "plt.xlabel('X-direction')\n",
    "plt.ylabel('Y-direction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cyan dots represent the optimized path and the blue dots represent the unoptimized path. As can be seen for the optimized path only the waypoints where the robot needs to change its orientation, are retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## complete pathplanning demonstration\n",
    "To see the complete Pathplanning on the testing map inaction this section can be run. To get a explanation of each part, see in the previous chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports needed to run pathplanning\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "#import pathplanning class\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "from pathPlanning import pathPlaning\n",
    "\n",
    "#load a testing map from image and convert it into a numpy array \n",
    "#(based on: https://www.pluralsight.com/guides/importing-image-data-into-numpy-arrays)\n",
    "pil_imgray = Image.open('Images/obstaclesTestMap.jpg').convert('LA')\n",
    "img = np.array(list(pil_imgray.getdata(band=0)), float)\n",
    "img.shape = (pil_imgray.size[1], pil_imgray.size[0])\n",
    "img=img<200\n",
    "occupancyGrid=img.astype(int)\n",
    "plt.imshow(occupancyGrid)\n",
    "##generate pathplanning object for the occupancy grid generated by the testmap\n",
    "pathPlanner=pathPlaning(occupancyGrid.copy(),1,1)#occipied cells are marked with a 1 and 1 cm per pixel\n",
    "\n",
    "#--set goal\n",
    "startTimer=timer()    #execution time when goal is set once\n",
    "#set goal\n",
    "goal=np.array([90,15])\n",
    "pathPlanner.setGoal(goal)\n",
    "\n",
    "endTimer=timer()\n",
    "print(\"Time needed for planning goal:\",endTimer-startTimer)\n",
    "#---set path\n",
    "startTimer=timer()\n",
    "start=np.array([10,75])\n",
    "pathPlanner.setStart(start)\n",
    "endTimer=timer()\n",
    "print(\"Time needed for the query for a new path:\",endTimer-startTimer)\n",
    "\n",
    "#--- get unoptimized path\n",
    "unoptimizedPath=pathPlanner.getPath()\n",
    "#-- get optimized Path\n",
    "optimizedPath=pathPlanner.getOptimizedPath()\n",
    "#--- draw all the components onto the same picture\n",
    "\n",
    "#make the distance map visible\n",
    "distanceGrid=pathPlanner.getDistanceMap()\n",
    "fillUp=np.zeros_like(occupancyGrid)#helper to make picture 3 colors\n",
    "maxValue=np.amax(distanceGrid.transpose())   # normalize values to fit into picture\n",
    "#create picture to show  map and distance map\n",
    "pic=np.dstack((occupancyGrid,np.divide(distanceGrid,maxValue),fillUp))\n",
    "plt.imshow(pic)\n",
    "plt.scatter(goal[0],goal[1],marker=\"o\", color = 'yellow',s=200)\n",
    "plt.xlabel('X-direction')\n",
    "plt.ylabel('Y-direction')\n",
    "plt.plot(unoptimizedPath[0], unoptimizedPath[1], marker=\"o\", color = 'blue');\n",
    "plt.scatter(optimizedPath[0],optimizedPath[1], marker=\"o\", color = 'cyan',s=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue points represent the unoptimized path, the cyan points are the optimized paths waypoint and red are the occupied cells. The green shade represents the distance of that pixel(cell) to the goal. The greener the longer is the path to the goal from that pixel(cell)\n",
    "As can be seen the path follows closely the obstacle. To prevent the robot from colliding with the obstacles, they need to be enlarged in the occupancy grid before the occupancy grid is given to the constructor. To see different behaviors the goal and start can be changed freely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lower = np.array([20,50,90])\n",
    "        upper = np.array([100,100,255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "cv2.namedWindow(\"preview\")\n",
    "cameraIndex=1             #TODO: change it to the correct camera. currently uses webcam\n",
    "sat=10\n",
    "exp=-6\n",
    "videoCapture = cv2.VideoCapture(cameraIndex)\n",
    "videoCapture.set(cv2.CAP_PROP_EXPOSURE,-6)\n",
    "videoCapture.set(cv2.CAP_PROP_SATURATION ,10)\n",
    "if not(videoCapture.isOpened()):\n",
    "    raise Exception('could not connect to camera')\n",
    "\n",
    "if videoCapture.isOpened(): # try to get the first frame\n",
    "    rval, frame = videoCapture.read()\n",
    "else:\n",
    "    rval = False\n",
    "    print(\"no image\")\n",
    "\n",
    "while rval:\n",
    "    cv2.imshow(\"preview\", frame)\n",
    "    rval, frame = videoCapture.read()\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27: # exit on ESC\n",
    "        break\n",
    "    elif(key== ord('w')):\n",
    "        exp=exp+0.1\n",
    "        print (videoCapture.set(cv2.CAP_PROP_EXPOSURE,exp),exp)\n",
    "    elif(key== ord('s')):    \n",
    "        exp=exp-0.1\n",
    "        print (videoCapture.set(cv2.CAP_PROP_EXPOSURE,exp),exp)\n",
    "cv2.destroyWindow(\"preview\")\n",
    "cv2.destroyAllWindows() \n",
    "cv2.VideoCapture(cameraIndex).release()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "497.208px",
    "left": "281.667px",
    "right": "20px",
    "top": "62px",
    "width": "749px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
